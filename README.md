#alpha-beta的中国象棋博弈程序

## 算法原理

**Minmax搜索**中国象棋属于零和博弈，所有的状态都可以用博弈树来表示，两个玩家的行动逐层交替出现，双方都要找到最优的节点。以根节点A一方的值来评估，A的每一层都要最大化MAX得分，另一方B要最小化MIN得分，即Minmax搜索。
* **alpha-beta剪枝**随着博弈层数增加，博弈树的节点数量呈指数型增长，可以通过alpha-beta剪枝赖剪掉不影响决策的分支：对于Max节点进行alpha剪枝（当效益值 ≥ beta值时剪枝）；Min节点进行beta剪枝（当效益值 ≤ alpha值剪枝）

## 优化操作

1. **历史表**：由于每次搜索的时候都会有很多个Max和Min搜索最优的路径，但只采用了最优的action，于是可以将每个Min和Max搜索的最优解的局面都增加一定的分值，当一个局面出现多次表明该下法是一个很好的走法，在搜索时应当优先搜索，所以我用历史表记录了红/黑方从src走到des的得分(因为从一个坐标src到des, 也有包含了对应棋子的信息(不同棋子的移动方式不同))，每次Max和Min得到best_action时就增加该走法的得分，在每次Max或Min搜索所有的走法前 *先根据启发表排序all_actions*, 并在结尾更新最优步骤到历史启发表中，使得能够选取更好的走法来进行alpha-beta剪枝（经过计算，加了历史表速度提升了5倍，使得原本只能在短时间内搜索4层增加到了搜索5层）
2. **搜索算法**：一开始我用的是普通的alpha-beta剪枝的Minmax搜索，后面由于当节点数量较少的时候，每一层搜索的节点数量大大减少，应该可以加深搜索，所以我换成了基于**IDA迭代加深的alpha-beta剪枝的Minmax搜索**，设置了当倒数第二层时间小于0.3s时就可以就加深搜索，使得本来保持搜索深度为4层变成了当局面较少时可以搜索到6层，且由于历史表的存在，使得当搜索深度大时可以利用搜索深度小时记录的值来更快进行
3. **棋局评估**：最开始我用的是**棋子棋力**+**棋子位置**的得分来作为评估函数，由于评估函数简单，所以可以将搜索层数设置到5层，虽然经过多个人的检验，效果能达到普通人的水平，但评估算法过于简单，不能较好的分析防守、进攻等关系，所以我添加了**棋子的机动性**和**棋子间的关系**来作为得分：机动性指棋子可以行动到的空位置数量\*得分，棋子间的关系指每个棋子受到多少个敌方棋子的进攻和多少个己方棋子的守护，分析当敌方进攻时如果直接吃、一换二、二换三、n换n等走法时己方和敌方的得分。加了新的得分评估后，搜索层数就需要减少到4层，但在第四层的评估函数中分析了局面的进攻和防守等关系，效果比原本的5层还要好，且IDA的存在可以加深搜索深度
4. **重复局面的优化**：因为Minmax搜索算法会选择最优的步骤，导致可能出现重复局面或者长将的局面，于是我通过记录最近的5个局面来防止电脑重复走相同的步骤。直接记录整个棋局过于复杂，经过网上多种记录局面的方法，我采用的是**zobrist效验码**来记录棋局，初始时遍历棋局记录初始zobrist值，后面每一次行动都只用简单异或计算即可得到新的局面的zobrist值；而且我通过一个循环队列记录5个zobrist值，每次电脑选择走法前先判断是否出现过该局面，不出现才可以走。加了该方法后，电脑至少在5步内不会出现重复走法和长将的局面。